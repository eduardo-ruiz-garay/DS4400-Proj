{
  "cells": [
    {
<<<<<<< HEAD
=======
      "cell_type": "markdown",
      "id": "0a5f78b6",
      "metadata": {
        "id": "0a5f78b6"
      },
      "source": [
        "\n",
        "Data Dictionary and Overview (from Kaggle https://www.kaggle.com/datasets/udaymalviya/bank-loan-data?resource=download)\n",
        "\n",
        "This dataset contains 45,000 records of loan applicants, with various attributes related to personal demographics, financial status, and loan details.\n",
        "\n",
        "Personal Information\n",
        "\n",
        "person_age: Age of the applicant (in years).\n",
        "\n",
        "person_gender: Gender of the applicant (male, female).\n",
        "\n",
        "person_education: Educational background (High School, Bachelor, Master, etc.).\n",
        "\n",
        "person_income: Annual income of the applicant (in USD).\n",
        "\n",
        "person_emp_exp: Years of employment experience.\n",
        "\n",
        "person_home_ownership: Type of home ownership (RENT, OWN, MORTGAGE).\n",
        "\n",
        "\n",
        "Loan Details\n",
        "\n",
        "loan_amnt: Loan amount requested (in USD).\n",
        "\n",
        "loan_intent: Purpose of the loan (PERSONAL, EDUCATION, MEDICAL, etc.).\n",
        "\n",
        "loan_int_rate: Interest rate on the loan (percentage).\n",
        "\n",
        "loan_percent_income: Ratio of loan amount to income.\n",
        "\n",
        "\n",
        "Credit & Loan History\n",
        "\n",
        "cb_person_cred_hist_length: Length of the applicant\"s credit history (in years).\n",
        "\n",
        "credit_score: Credit score of the applicant.\n",
        "\n",
        "previous_loan_defaults_on_file: Whether the applicant has previous loan defaults (Yes or No).\n",
        "\n",
        "\n",
        "\n",
        "Target Variable\n",
        "\n",
        "loan_status: 1 if the loan was repaid successfully, 0 if the applicant defaulted.\n"
      ]
    },
    {
>>>>>>> 089c65b4f8fc32fa07773919ef5700f49ff55dea
      "cell_type": "code",
      "execution_count": 16,
      "id": "6356b348",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6356b348",
        "outputId": "2fd9856c-c44c-4439-a866-11f4bce9a81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows with null values: 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Step 1 Clean the data\n",
        "df = pd.read_csv(\"../loan_data.csv\")\n",
        "\n",
        "# See if there are rows with nulls that need to be removed\n",
        "rows_with_nulls = df.isna().any(axis=1).sum()\n",
        "print(f\"Number of rows with null values: {rows_with_nulls}\")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 17,
=======
      "execution_count": null,
>>>>>>> 089c65b4f8fc32fa07773919ef5700f49ff55dea
      "id": "3fc75f13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fc75f13",
        "outputId": "610cb1e9-d890-480f-813a-115fcb31236d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         person_age  person_income  person_emp_exp     loan_amnt  \\\n",
            "count  45000.000000   4.500000e+04    45000.000000  45000.000000   \n",
            "mean      27.764178   8.031905e+04        5.410333   9583.157556   \n",
            "std        6.045108   8.042250e+04        6.063532   6314.886691   \n",
            "min       20.000000   8.000000e+03        0.000000    500.000000   \n",
            "25%       24.000000   4.720400e+04        1.000000   5000.000000   \n",
            "50%       26.000000   6.704800e+04        4.000000   8000.000000   \n",
            "75%       30.000000   9.578925e+04        8.000000  12237.250000   \n",
            "max      144.000000   7.200766e+06      125.000000  35000.000000   \n",
            "\n",
            "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
            "count   45000.000000         45000.000000                45000.000000   \n",
            "mean       11.006606             0.139725                    5.867489   \n",
            "std         2.978808             0.087212                    3.879702   \n",
            "min         5.420000             0.000000                    2.000000   \n",
            "25%         8.590000             0.070000                    3.000000   \n",
            "50%        11.010000             0.120000                    4.000000   \n",
            "75%        12.990000             0.190000                    8.000000   \n",
            "max        20.000000             0.660000                   30.000000   \n",
            "\n",
            "       credit_score   loan_status  \n",
            "count  45000.000000  45000.000000  \n",
            "mean     632.608756      0.222222  \n",
            "std       50.435865      0.415744  \n",
            "min      390.000000      0.000000  \n",
            "25%      601.000000      0.000000  \n",
            "50%      640.000000      0.000000  \n",
            "75%      670.000000      0.000000  \n",
            "max      850.000000      1.000000  \n"
          ]
        }
      ],
      "source": [
        "# Step 2 Some basic EDA\n",
<<<<<<< HEAD
        "print(df.describe())"
=======
        "print(df.describe(include=\"all\"))"
>>>>>>> 089c65b4f8fc32fa07773919ef5700f49ff55dea
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 18,
=======
      "execution_count": null,
>>>>>>> 089c65b4f8fc32fa07773919ef5700f49ff55dea
      "id": "58f3fe8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "58f3fe8f",
        "outputId": "5ff859d1-ed66-423c-bff4-c5f66e0e96cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_age</th>\n",
              "      <th>person_gender</th>\n",
              "      <th>person_education</th>\n",
              "      <th>person_income</th>\n",
              "      <th>person_emp_exp</th>\n",
              "      <th>person_home_ownership</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>loan_intent</th>\n",
              "      <th>loan_int_rate</th>\n",
              "      <th>loan_percent_income</th>\n",
              "      <th>cb_person_cred_hist_length</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>previous_loan_defaults_on_file</th>\n",
              "      <th>loan_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>female</td>\n",
              "      <td>Master</td>\n",
              "      <td>71948.0</td>\n",
              "      <td>0</td>\n",
              "      <td>RENT</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>PERSONAL</td>\n",
              "      <td>16.02</td>\n",
              "      <td>0.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>561</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.0</td>\n",
              "      <td>female</td>\n",
              "      <td>High School</td>\n",
              "      <td>12282.0</td>\n",
              "      <td>0</td>\n",
              "      <td>OWN</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>EDUCATION</td>\n",
              "      <td>11.14</td>\n",
              "      <td>0.08</td>\n",
              "      <td>2.0</td>\n",
              "      <td>504</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.0</td>\n",
              "      <td>female</td>\n",
              "      <td>High School</td>\n",
              "      <td>12438.0</td>\n",
              "      <td>3</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>5500.0</td>\n",
              "      <td>MEDICAL</td>\n",
              "      <td>12.87</td>\n",
              "      <td>0.44</td>\n",
              "      <td>3.0</td>\n",
              "      <td>635</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23.0</td>\n",
              "      <td>female</td>\n",
              "      <td>Bachelor</td>\n",
              "      <td>79753.0</td>\n",
              "      <td>0</td>\n",
              "      <td>RENT</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>MEDICAL</td>\n",
              "      <td>15.23</td>\n",
              "      <td>0.44</td>\n",
              "      <td>2.0</td>\n",
              "      <td>675</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Master</td>\n",
              "      <td>66135.0</td>\n",
              "      <td>1</td>\n",
              "      <td>RENT</td>\n",
              "      <td>35000.0</td>\n",
              "      <td>MEDICAL</td>\n",
              "      <td>14.27</td>\n",
              "      <td>0.53</td>\n",
              "      <td>4.0</td>\n",
              "      <td>586</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
              "0        22.0        female           Master        71948.0               0   \n",
              "1        21.0        female      High School        12282.0               0   \n",
              "2        25.0        female      High School        12438.0               3   \n",
              "3        23.0        female         Bachelor        79753.0               0   \n",
              "4        24.0          male           Master        66135.0               1   \n",
              "\n",
              "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
              "0                  RENT    35000.0    PERSONAL          16.02   \n",
              "1                   OWN     1000.0   EDUCATION          11.14   \n",
              "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
              "3                  RENT    35000.0     MEDICAL          15.23   \n",
              "4                  RENT    35000.0     MEDICAL          14.27   \n",
              "\n",
              "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
              "0                 0.49                         3.0           561   \n",
              "1                 0.08                         2.0           504   \n",
              "2                 0.44                         3.0           635   \n",
              "3                 0.44                         2.0           675   \n",
              "4                 0.53                         4.0           586   \n",
              "\n",
              "  previous_loan_defaults_on_file  loan_status  \n",
              "0                             No            1  \n",
              "1                            Yes            0  \n",
              "2                             No            1  \n",
              "3                             No            1  \n",
              "4                             No            1  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View df\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 19,
=======
      "execution_count": 2,
>>>>>>> 089c65b4f8fc32fa07773919ef5700f49ff55dea
      "id": "173a3248",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "173a3248",
        "outputId": "9f1c6a1c-15be-4344-988a-be06d70b684e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns after preprocessing: 22\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 3 Preprocess\n",
        "\n",
        "# Convert yes no column to boolean\n",
        "loans_bool = (np.where(df[\"previous_loan_defaults_on_file\"] == \"Yes\", True, False)).reshape(-1, 1)\n",
        "\n",
        "# Seperate out dependent variable\n",
        "y = df[\"loan_status\"]\n",
        "\n",
        "\n",
        "# Numerical Variables\n",
        "numerical = df[[\"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"]]\n",
        "\n",
        "# Min Max scale numerical data\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "numerical_scaled = scaler.fit_transform(numerical)\n",
        "\n",
        "\n",
        "# Categorical Variables\n",
        "categorical = df[[\"person_gender\", \"person_education\", \"person_home_ownership\", \"loan_intent\"]]\n",
        "categorical_dummies = pd.get_dummies(categorical, drop_first=True)\n",
        "categorical_dummies_array = np.array(categorical_dummies)\n",
        "\n",
        "# Column names / order\n",
        "columns = list(numerical.columns) + list(categorical_dummies.columns) + [\"previous_loan_defaults_on_file\"]\n",
        "\n",
        "# Create Phi with numerical, categorical, and boolean variables\n",
        "Phi = np.hstack((numerical_scaled, categorical_dummies_array, loans_bool))\n",
        "\n",
        "print(f\"Number of columns after preprocessing: {Phi.shape[1]}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(Phi, y, test_size=0.2, random_state=23)\n",
        "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 20,
=======
      "execution_count": 7,
>>>>>>> 089c65b4f8fc32fa07773919ef5700f49ff55dea
      "id": "08e3b1f4",
      "metadata": {
        "id": "08e3b1f4"
      },
      "outputs": [],
      "source": [
        "# KNN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_knn(X_train, y_train, X_test, y_test, k):\n",
        "    predictions = []\n",
        "\n",
        "    for test_point in X_test:\n",
        "        # L2 distances\n",
        "        distances = np.sqrt(np.sum((X_train - test_point) ** 2, axis=1))\n",
        "\n",
        "        # K nearest neighbors\n",
        "        knn_indices = np.argsort(distances)[:k]\n",
        "        knn_labels = y_train[knn_indices]\n",
        "\n",
        "        # Calculate mode\n",
        "        unique_values, counts = np.unique(knn_labels, return_counts=True)\n",
        "        mode_index = np.argmax(counts)\n",
        "        predicted_class = unique_values[mode_index]\n",
        "\n",
        "        predictions.append(predicted_class)\n",
        "\n",
        "    # Prediction accuracy\n",
        "    y_pred = np.array(predictions)\n",
        "    accuracy = np.mean(y_pred == y_test)\n",
        "    return accuracy, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "15a5fa9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "15a5fa9d",
        "outputId": "e37a5cf0-a9d3-4cea-86d9-f34357f9475c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K = 5, Accuracy: 0.8881\n",
            "K = 10, Accuracy: 0.8914\n",
            "K = 25, Accuracy: 0.8950\n",
            "K = 50, Accuracy: 0.8909\n",
            "K = 75, Accuracy: 0.8854\n",
            "K = 100, Accuracy: 0.8742\n",
            "K = 125, Accuracy: 0.8697\n"
          ]
        }
      ],
      "source": [
        "# Params\n",
        "n = X_train.shape[0]\n",
        "sqrt_n = int(np.sqrt(n).round())  # 190\n",
        "\n",
        "k_values = [5, 10, 25, 50, 75, 100, 125, 150, 175, sqrt_n, 200, 225, 250]   # Some test ks\n",
        "\n",
        "\n",
        "# Run KNN for different k values in a for loop\n",
        "accuracies = []\n",
        "for k in k_values:\n",
        "    accuracy, y_pred = run_knn(X_train, y_train, X_test, y_test, k)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"K = {k}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Plot k vs accuracy\n",
        "plt.plot(k_values, accuracies)\n",
        "plt.xlabel(\"Number of Neighbors (k)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"KNN Accuracy vs Number of Neighbors\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5736319d",
      "metadata": {
        "id": "5736319d",
        "outputId": "975a47b3-deb0-4619-e094-6b1aefdbc8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K = 25, Accuracy: 0.8950\n",
            "Precision: 0.8333\n",
            "Recall: 0.6608\n",
            "F1 Score: 0.7371\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6730  265]\n",
            " [ 680 1325]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93      6995\n",
            "           1       0.83      0.66      0.74      2005\n",
            "\n",
            "    accuracy                           0.90      9000\n",
            "   macro avg       0.87      0.81      0.84      9000\n",
            "weighted avg       0.89      0.90      0.89      9000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Best k was 25\n",
        "k = 25\n",
        "accuracy, predictions = run_knn(X_train, y_train, X_test, y_test, k)\n",
        "y_pred = np.array(predictions)\n",
        "print(f\"K = {k}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Precision, recall, and F1 score\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "480a1825",
      "metadata": {
        "id": "480a1825"
      },
      "source": [
        "The best k was clearly 25 (though this is also very dependent on the random state), and the results were decently strong with an accuracy of 90% correct predictions. There is clearly a strong class imbalance with more 0s than 1s, and the model is not handling that very well with significantly lower prediction accuracies for predicting a 1 than a 0. This could potentially be improved by imputing some dummy data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3196ab3",
      "metadata": {
        "id": "f3196ab3",
        "outputId": "7831a5a7-1605-494a-f20b-613cdb047eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      6995\n",
            "           1       0.90      0.75      0.82      2005\n",
            "\n",
            "    accuracy                           0.93      9000\n",
            "   macro avg       0.91      0.86      0.89      9000\n",
            "weighted avg       0.92      0.93      0.92      9000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6818  177]\n",
            " [ 493 1512]]\n",
            "\n",
            "Feature Importance:\n",
            "                           Feature  Importance\n",
            "21  previous_loan_defaults_on_file    0.284019\n",
            "4                    loan_int_rate    0.140659\n",
            "5              loan_percent_income    0.139325\n",
            "1                    person_income    0.113094\n",
            "3                        loan_amnt    0.059230\n",
            "7                     credit_score    0.053026\n",
            "15      person_home_ownership_RENT    0.047536\n",
            "0                       person_age    0.031821\n",
            "2                   person_emp_exp    0.028236\n",
            "6       cb_person_cred_hist_length    0.026445\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# We can use the same train test as scaling should not matter for random forest\n",
        "\n",
        "rf = RandomForestClassifier(max_depth=None, random_state=23, criterion=\"entropy\")\n",
        "\n",
        "# Train the model\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Model performance\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = rf.feature_importances_\n",
        "feature_names = [f\"Feature {i}\" for i in range(Phi.shape[1])]\n",
        "\n",
        "# Make feature importance and display top 10\n",
        "importance_df = pd.DataFrame({\"Feature\": columns, \"Importance\": feature_importance})\n",
        "importance_df = importance_df.sort_values(\"Importance\", ascending=False)\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(importance_df.head(10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6756b6a4",
      "metadata": {
        "id": "6756b6a4"
      },
      "source": [
        "The model does better at predicting 0s (defaulting the loan) than 1s (completing the payment). This is likely due to a strong class imbalance with more 0s than 1s in the dataset. Despite the strong imbalance, the model results were relatively good with an accuracy of 93% correct predictions. The model is clearly better than the knn, and significantly outperforms it for predicting 1s.\n",
        "\n",
        "The most important features that provided the best splits were the persons yearly income, the loan percent of the income, the loan interest rate, and by far if the person had previous loan defaults on file. These all make a lot of sense as they seem incredibly relevant to the prediction. All of these statistics are very strongly correlated, so I wonder if they are not all necessary in a simplified model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e4c2f0b",
      "metadata": {
        "id": "9e4c2f0b"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "def sigmoid(x, w):\n",
        "    return 1/(1 + np.exp(-x.T.dot(w)))\n",
        "\n",
        "def logistic_grad(X, y, w):\n",
        "    L = 0\n",
        "    for i, j in enumerate(X):\n",
        "        x = j.reshape(X.shape[1], 1)\n",
        "        L += (sigmoid(x, w) - y[i])*x\n",
        "\n",
        "    dL_dw = L/len(X)\n",
        "    return dL_dw\n",
        "\n",
        "def gradient_descent(X, y, w, eta, epochs):\n",
        "    for i in range(epochs):\n",
        "        w = w - eta*logistic_grad(X, y, w)\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0c5900c",
      "metadata": {
        "id": "a0c5900c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "# Params\n",
        "w0 = np.ones(X_train.shape[1]).reshape(-1, 1)\n",
        "eta = 0.1\n",
        "epochs = 2000\n",
        "\n",
        "# Run Gradient Descent to (hopefully) improve predictions\n",
        "w_gd = gradient_descent(X_train, y_train, w0, eta, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "WlyKU-nv450i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlyKU-nv450i",
        "outputId": "60498670-bf64-46d1-f19e-4d8697a6fcd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the algorithm: 0.8803333333333333\n",
            "Precision of the algorithm: 0.7473347547974414\n",
            "Recall of the algorithm: 0.6992518703241896\n",
            "F1 Score of the algorithm: 0.7224942025251224\n",
            "                           Feature    Weight  Abs Weight\n",
            "21  previous_loan_defaults_on_file -4.355207    4.355207\n",
            "7                     credit_score -2.559459    2.559459\n",
            "5              loan_percent_income  1.902508    1.902508\n",
            "4                    loan_int_rate  1.586531    1.586531\n",
            "13     person_home_ownership_OTHER  0.962303    0.962303\n",
            "15      person_home_ownership_RENT  0.947924    0.947924\n",
            "1                    person_income  0.865446    0.865446\n",
            "20             loan_intent_VENTURE -0.717456    0.717456\n",
            "16           loan_intent_EDUCATION -0.574137    0.574137\n",
            "2                   person_emp_exp  0.554522    0.554522\n",
            "10      person_education_Doctorate  0.533120    0.533120\n",
            "0                       person_age  0.435048    0.435048\n",
            "19            loan_intent_PERSONAL -0.415268    0.415268\n",
            "6       cb_person_cred_hist_length -0.283370    0.283370\n",
            "14       person_home_ownership_OWN -0.275163    0.275163\n",
            "9        person_education_Bachelor -0.224752    0.224752\n",
            "12         person_education_Master -0.205888    0.205888\n",
            "11    person_education_High School -0.185534    0.185534\n",
            "8               person_gender_male -0.157230    0.157230\n",
            "3                        loan_amnt  0.079091    0.079091\n",
            "18             loan_intent_MEDICAL -0.061515    0.061515\n",
            "17     loan_intent_HOMEIMPROVEMENT  0.028839    0.028839\n"
          ]
        }
      ],
      "source": [
        "# Evaluate logistic regression model\n",
        "preds = []\n",
        "for i in range(X_test.shape[0]):\n",
        "    preds.append(int(sigmoid(X_test[i,:], w_gd)[0] > .5))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat = confusion_matrix(y_true=y_test, y_pred=preds)\n",
        "true_positive = conf_mat[1,1]\n",
        "false_positive = conf_mat[0,1]\n",
        "true_negative = conf_mat[0,0]\n",
        "false_negative = conf_mat[1,0]\n",
        "\n",
        "# Calculate and print model results\n",
        "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_negative + false_positive)\n",
        "precision = true_positive / (true_positive + false_positive)\n",
        "recall = true_positive / (true_positive + false_negative)\n",
        "F1_score = (2*true_positive) / (2*true_positive + false_positive + false_negative)\n",
        "\n",
        "print(f\"Accuracy of the algorithm: {accuracy}\")\n",
        "print(f\"Precision of the algorithm: {precision}\")\n",
        "print(f\"Recall of the algorithm: {recall}\")\n",
        "print(f\"F1 Score of the algorithm: {F1_score}\")\n",
        "\n",
        "\n",
        "\n",
        "# Create and sort importance dataframe\n",
        "importance_df = pd.DataFrame({\"Feature\": columns, \"Weight\": w_gd.reshape(-1), \"Abs Weight\": np.abs(w_gd.reshape(-1))})\n",
        "importance_df = importance_df.sort_values(\"Abs Weight\", ascending=False)\n",
        "print(importance_df)\n",
        "# print(w_gd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7ca86144",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns after preprocessing: 22\n"
          ]
        }
      ],
      "source": [
        "# Scaling data differently for LDA, PCA, and SVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standard scale numerical data\n",
        "scaler =  StandardScaler()\n",
        "numerical_scaled = scaler.fit_transform(numerical)\n",
        "\n",
        "\n",
        "# Create Phi with numerical, categorical, and boolean variables\n",
        "Phi_standard = np.hstack((numerical_scaled, categorical_dummies_array, loans_bool))\n",
        "\n",
        "print(f\"Number of columns after preprocessing: {Phi_standard.shape[1]}\")\n",
        "\n",
        "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(Phi_standard, y, test_size=0.2, random_state=23)\n",
        "X_train_standard, y_train_standard, X_test_standard, y_test_standard = np.array(X_train_standard), np.array(y_train_standard), np.array(X_test_standard), np.array(y_test_standard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "17VuOBdK1cWc",
      "metadata": {
        "id": "17VuOBdK1cWc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8901111111111111\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x13553d8b610>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 2d space\n",
        "lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "\n",
        "# Train model\n",
        "lda.fit(X_train_standard, y_train_standard)\n",
        "\n",
        "# Predict on the Test Set\n",
        "y_pred = lda.predict(X_test_standard)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_standard, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "X_transformed = lda.transform(Phi_standard)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for class_value in np.unique(y):\n",
        "    class_data = X_transformed[y == class_value]\n",
        "    plt.hist(class_data, alpha=0.5, bins=30, density=True, \n",
        "             label=f'Class {class_value}')\n",
        "plt.xlabel(\"LDA Component 1\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"LDA Component Distribution by Class\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d669f00",
      "metadata": {},
      "source": [
        "Because it is a binary classification, we only can have one component as there is only one hyperplane division to split the components. There is some clear overlap, which is expected, but the model does a surprisingly strong job seperating the data on just one hyperplane. Would be interesting to see if SVM has a similar division."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "46df3566",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8958888888888888\n",
            "Precision: 0.7822410147991543\n",
            "Recall: 0.7381546134663342\n",
            "F1 Score: 0.7595586348473184\n"
          ]
        }
      ],
      "source": [
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear', C=1)\n",
        "svm.fit(X_train_standard, y_train_standard)\n",
        "\n",
        "# Predict on test\n",
        "y_pred_full = svm.predict(X_test_standard)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat = confusion_matrix(y_test_standard, y_pred_full)\n",
        "true_positive = conf_mat[1,1]\n",
        "false_positive = conf_mat[0,1]\n",
        "true_negative = conf_mat[0,0]\n",
        "false_negative = conf_mat[1,0]\n",
        "\n",
        "# Calculate and print model results\n",
        "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_negative + false_positive)\n",
        "precision = true_positive / (true_positive + false_positive)\n",
        "recall = true_positive / (true_positive + false_negative)\n",
        "F1_score = (2*true_positive) / (2*true_positive + false_positive + false_negative)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {F1_score}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
